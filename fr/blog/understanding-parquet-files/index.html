<!doctype html><html lang=fr><head><meta charset=UTF-8><meta content="default-src 'self';font-src 'self' data:;frame-src platform.twitter.com giscus.app;img-src 'self' data: pub-94e31bf482a74272bb61e9559b598705.r2.dev;media-src 'self' pub-94e31bf482a74272bb61e9559b598705.r2.dev;form-action 'self' buttondown.com formspree.io;connect-src 'self';script-src 'self' platform.twitter.com giscus.app" http-equiv=Content-Security-Policy><meta content="width=device-width,initial-scale=1.0" name=viewport><meta content=https://vinidlidoo.github.io name=base><title>
vinidlidoo • Quand Parquet supplante CSV</title><link href=https://vinidlidoo.github.io/img/favicon.png rel=icon type=image/png><link href="https://vinidlidoo.github.io/custom_subset.css?h=0b9535a28bc3d5bf2321" rel=stylesheet><link href="https://vinidlidoo.github.io/main.css?h=045c365e19a4d50a64bb" rel=stylesheet><link href="https://vinidlidoo.github.io/css/details.css?h=8559b4e109b168c7cfa0" rel=stylesheet><link href="https://vinidlidoo.github.io/css/giscus-fix.css?h=dc895b97fbaf0f0d9908" rel=stylesheet><link href="https://vinidlidoo.github.io/css/newsletter.css?h=c872153c9c367e0bee16" rel=stylesheet><link href="https://vinidlidoo.github.io/css/contact.css?h=572915e83e02eb90c290" rel=stylesheet><link href="https://vinidlidoo.github.io/css/details.css?h=8559b4e109b168c7cfa0" rel=stylesheet><link href="https://vinidlidoo.github.io/skins/indigo_ingot.css?h=d429472afbb246441b1a" rel=stylesheet><meta content="light dark" name=color-scheme><meta content="La réalité physique qui rend la disposition des fichiers déterminante" name=description><meta content="La réalité physique qui rend la disposition des fichiers déterminante" property=og:description><meta content="Quand Parquet supplante CSV" property=og:title><meta content=article property=og:type><meta content="https://vinidlidoo.github.io/img/row-vs-column-orientation.webp?h=00928d4da4f88e2456da" property=og:image><meta content=1200 property=og:image:width><meta content=670 property=og:image:height><meta content="https://vinidlidoo.github.io/img/row-vs-column-orientation.webp?h=00928d4da4f88e2456da" name=twitter:image><meta content=summary_large_image name=twitter:card><meta content=en_GB property=og:locale:alternate><link href=https://vinidlidoo.github.io/ja/blog/understanding-parquet-files/ hreflang=ja rel=alternate><meta content=en_GB property=og:locale:alternate><link href=https://vinidlidoo.github.io/blog/understanding-parquet-files/ hreflang=en rel=alternate><meta content=en_GB property=og:locale:alternate><link href=https://vinidlidoo.github.io/fr/blog/understanding-parquet-files/ hreflang=fr rel=alternate><meta content=https://vinidlidoo.github.io/fr/blog/understanding-parquet-files/ property=og:url><meta content=vinidlidoo property=og:site_name><noscript><link href=https://vinidlidoo.github.io/no_js.css rel=stylesheet></noscript><script src=https://vinidlidoo.github.io/js/initializeTheme.min.js></script><script defer src=https://vinidlidoo.github.io/js/themeSwitcher.min.js></script><script src="https://vinidlidoo.github.io/js/searchElasticlunr.min.js?h=3626c0ef99daa745b31e" defer></script><script defer src=https://vinidlidoo.github.io/js/lunr/lunrStemmerSupport.min.js></script><script defer src=https://vinidlidoo.github.io/js/lunr/lunr.fr.min.js></script><body><a href=#main-content id=skip-link>Skip to content</a><header><nav class=navbar><div class=nav-title><a class=home-title href=https://vinidlidoo.github.io/fr/>vinidlidoo</a></div><div class=nav-navs><ul><li><a class="nav-links no-hover-padding" href=https://vinidlidoo.github.io/fr/blog/>blog </a><li><a class="nav-links no-hover-padding" href=https://vinidlidoo.github.io/fr/tags/>étiquettes </a><li><a class="nav-links no-hover-padding" href=https://vinidlidoo.github.io/fr/contact/>contact </a><li class=menu-icons-container><ul class=menu-icons-group><li class="js menu-icon"><div aria-label="Press $SHORTCUT to open search" class="search-icon interactive-icon" title="Press $SHORTCUT to open search" id=search-button role=button tabindex=0><svg viewbox="0 -960 960 960" xmlns=http://www.w3.org/2000/svg><path d="M784-120 532-372q-30 24-69 38t-83 14q-109 0-184.5-75.5T120-580q0-109 75.5-184.5T380-840q109 0 184.5 75.5T640-580q0 44-14 83t-38 69l252 252-56 56ZM380-400q75 0 127.5-52.5T560-580q0-75-52.5-127.5T380-760q-75 0-127.5 52.5T200-580q0 75 52.5 127.5T380-400Z"/></svg></div><li class=language-switcher><details class=dropdown><summary aria-label="Language selection" title="Language selection" aria-haspopup=true role=button><div class=language-switcher-icon></div></summary> <div class=dropdown-content role=menu>Français<a aria-label=English href=https://vinidlidoo.github.io/blog/understanding-parquet-files/ lang=en role=menuitem>English</a><a aria-label=日本語 href=https://vinidlidoo.github.io/ja/blog/understanding-parquet-files/ lang=ja role=menuitem>日本語</a></div></details><li class="theme-switcher-wrapper js"><div aria-label="Toggle dark mode" title="Toggle dark/light mode" aria-pressed=false class=theme-switcher role=button tabindex=0></div><div aria-label="Reset mode to default" class="theme-resetter arrow" title="Reset mode to default" aria-hidden=true role=button tabindex=0></div></ul></ul></div></nav></header><div class=content id=main-content><main><article class=h-entry><h1 class="p-name article-title">Quand Parquet supplante CSV</h1><a class="u-url u-uid" href=https://vinidlidoo.github.io/fr/blog/understanding-parquet-files/></a><ul class=meta><span class="hidden p-author h-card"> <a class=u-url href=https://vinidlidoo.github.io rel=author title=Vincent>Vincent</a> </span><li><time class=dt-published datetime=2026-01-23>23rd Jan 2026</time><li title="2327 words"><span aria-hidden=true class=separator>•</span>12 min read<li class=tag><span aria-hidden=true class=separator>•</span>Étiquettes: <li class=tag><a class=p-category href=https://vinidlidoo.github.io/fr/tags/computer-science/>computer-science</a></ul><ul class="meta last-updated"><li><time class=dt-updated datetime=2026-02-18>Updated on 18th Feb 2026</time><li><span aria-hidden=true class=separator>•</span><a class=external href=https://github.com/vinidlidoo/vinidlidoo.github.io/commits/main/content/blog/understanding-parquet-files.fr.md>See changes</a></ul><p class=p-summary hidden>La réalité physique qui rend la disposition des fichiers déterminante<section class="e-content body"><p><img alt="Stockage orienté ligne vs orienté colonne" src=/img/row-vs-column-orientation.webp><p>En décembre 2021, je dirigeais une nouvelle équipe chez Amazon, chargée de construire une application d'analyse de tendances. Nos données arrivaient dans S3 sous forme de fichiers CSV, étaient ingérées dans une base de données, puis alimentaient des traitements batch hebdomadaires. Un ingénieur data a proposé de passer du format CSV à Parquet. Un débat s'en est suivi. Parquet a gagné.<p>Je l'avoue : je n'ai jamais vraiment compris <em>pourquoi</em>. Quand j'ai demandé des explications, on m'a dit que le stockage en colonnes offrait de meilleures performances, une meilleure compression, et ainsi de suite. Ça semblait presque trop beau pour être vrai. Je n'avais pas une compréhension solide des compromis, encore moins des mécanismes derrière ces avantages. C'était mes premiers 90 jours dans ce rôle, alors j'ai fait comme beaucoup de managers : j'ai suivi mon instinct et je suis passé à autre chose. Cet article est ma tentative de finalement comprendre.<h2 id=les-fichiers-comme-tableaux-d-octets>Les fichiers comme tableaux d'octets</h2><p>Sur disque, les données d'un fichier sont stockées comme une <strong>séquence contiguë d'octets</strong> :<sup class=footnote-reference id=fr-1-1><a href=#fn-1>1</a></sup> $[b_0, b_1, b_2, \ldots, b_n]$ où chaque $b_i$ est un octet (8 bits, chacun 0 ou 1) et $n$ se compte typiquement en millions (Mo) voire milliards (Go) pour les traitements analytiques.<p>Les requêtes analytiques ont rarement besoin de toutes ces données. Une requête typique pourrait agréger une colonne, filtrer sur une autre, et ignorer le reste. Si un fichier a 100 colonnes et 10 millions de lignes, mais que la requête ne touche que 3 colonnes, lire le fichier entier signifie transférer 30 fois plus d'octets que nécessaire. À grande échelle—des centaines de fichiers de plusieurs gigaoctets chacun—cette surcharge domine. Lire des fichiers entiers n'est pas viable.<p>Il faut donc être chirurgical : extraire uniquement les octets dont on a réellement besoin.<p>Deux opérations permettent de faire cela :<ul><li><strong>seek</strong> : positionner la tête de lecture à l'octet $b_i$<li><strong>read</strong> : transférer les octets séquentiellement à partir de $b_i$</ul><p>La <strong>disposition</strong> du fichier détermine si les données dont on a besoin sont contiguës (un seul seek) ou dispersées (de nombreux seeks).<p>Mais il y a une contrainte : <strong>le seek est coûteux par rapport au read</strong>. Un disque dur traditionnel a une latence d'accès d'environ 10 ms (le seek) et un débit de 150 Mo/s (le read). Comparons :<ul><li>Lire 10 octets : 10 ms + ~0 ms = <strong>10 ms</strong><li>Lire 1 Mo : 10 ms + 6,7 ms = <strong>17 ms</strong></ul><p>Passer de 10 octets à 1 Mo (100 000 fois plus de données) ne double même pas le temps d'E/S si les données lues sont contiguës. L'objectif est clair : <strong>minimiser les seeks, maximiser les octets par seek</strong>. La stratégie qui permet d'y parvenir s'appelle le <strong>batching</strong> : lire de gros blocs contigus au lieu de nombreuses petites lectures dispersées dans le fichier.<p>Le même principe s'applique au stockage objet cloud comme S3. Les disques d'AWS ont toujours une surcharge de seek, mais de notre point de vue le goulot d'étranglement est la surcharge des requêtes HTTP (TCP, TLS, aller-retour). Le batching ici signifie demander de grandes plages d'octets par requête HTTP. Contrairement au disque (une seule tête de lecture), S3 permet d'émettre plusieurs requêtes en parallèle, mais la concurrence est limitée donc l'objectif reste le même : <strong>moins de requêtes avec des plages d'octets plus grandes</strong>.<div class="table-wrapper table-wide"><table><thead><tr><th>Stockage<th>Latence d'accès<th>Débit<th>Implication<tbody><tr><td>HDD<td>~10 ms (seek mécanique)<td>150 Mo/s<td>La latence domine ; le batching est essentiel<tr><td>SSD<sup class=footnote-reference id=fr-2-1><a href=#fn-2>2</a></sup><td>~0,1 ms (pas de pièces mobiles)<td>500–3000 Mo/s<td>Pénalité plus faible par seek ; le batching reste gagnant<tr><td>S3<td>~100 ms (aller-retour HTTP)<td>100+ Mo/s<td>Privilégier les grandes plages d'octets ; paralléliser entre chunks</table></div><h2 id=orientation-ligne-vs-colonne>Orientation ligne vs colonne</h2><p>Les données analytiques sont typiquement tabulaires : lignes et colonnes. Quand on sérialise une table en séquence d'octets, il y a deux choix naturels. Considérons une simple table d'employés :<div class=table-wrapper><table><thead><tr><th>name<th>age<th>salary<th>dept<tbody><tr><td>Alice<td>32<td>95000<td>Eng<tr><td>Bob<td>28<td>72000<td>Mkt<tr><td>Carol<td>45<td>120000<td>Eng</table></div><p><strong>Orienté ligne</strong> (CSV) : stocker chaque ligne de manière contiguë, puis la ligne suivante. <code>[Alice,32,95000,Eng][Bob,28,72000,Mkt][Carol,45,120000,Eng]</code><p><strong>Orienté colonne</strong> (Parquet) : stocker chaque colonne de manière contiguë, puis la colonne suivante. <code>[Alice,Bob,Carol][32,28,45][95000,72000,120000][Eng,Mkt,Eng]</code><p>Cela change quels octets on doit lire. Considérons <code>SELECT name, salary</code> : on a besoin de 2 colonnes sur 4.<p>Avec CSV, les colonnes sont entrelacées dans chaque ligne. On pourrait lire le fichier entier et ignorer ce dont on n'a pas besoin, mais on vient d'établir que ce n'est pas viable à grande échelle. Et si on avait un index indiquant exactement où commence chaque champ ? Pourrait-on alors se positionner directement sur name et salary et ne lire que ceux-là ?<p>On pourrait, mais ça n'aiderait pas. Pour lire 2 colonnes sur 1 million de lignes, il faudrait 2 millions de seeks séparés (un par champ). À 10 ms par seek sur HDD, c'est plus de 5 heures de temps de seek seul. Le problème n'est pas de savoir où sont les données. Le problème est que les données dont on a besoin sont <em>dispersées</em>. La disposition orientée ligne force soit à tout lire, soit à faire des millions de petites lectures. Aucune de ces options n'est acceptable.<p>La disposition en colonnes résout ce problème. Chaque colonne est stockée de manière contiguë, donc lire name et salary signifie deux seeks et deux lectures séquentielles. Les données dont on a besoin sont physiquement regroupées. Il suffit d'avoir un moyen de localiser où commence chaque colonne. C'est ce que Parquet fournit.<h2 id=structure-d-un-fichier-parquet>Structure d'un fichier Parquet</h2><p>Un fichier Parquet a trois composants clés :<p><img alt="Structure d'un fichier Parquet" src=/img/parquet-file-structure.webp><p>Sous forme de séquence d'octets :<pre><code>[RG0:Col0][RG0:Col1][RG0:Col2]...[RG1:Col0][RG1:Col1][RG1:Col2]...[Footer]
</code></pre><p>Les <strong>row groups</strong> (~128 Mo chacun) sont des partitions horizontales de lignes. Ils permettent le traitement parallèle : les moteurs de requêtes distribués comme Spark ou BigQuery peuvent assigner différents row groups à différents workers.<p>Les <strong>column chunks</strong> résident dans chaque row group. Les données de chaque colonne sont stockées de manière contiguë. C'est là qu'opère réellement le stockage en colonnes. Les column chunks sont ensuite divisés en <strong>pages</strong> (~1 Mo chacune), où l'encodage et la compression sont appliqués. On n'entrera pas dans le détail des pages ici.<p>Le <strong>footer</strong> est stocké à la fin du fichier et contient les métadonnées nécessaires pour lire chirurgicalement : l'offset (où se positionner), la taille (combien lire), et les statistiques (min/max/nulls) pour chaque column chunk de chaque row group.<p>Voici à quoi ressemble le footer (simplifié) :<pre><code>Footer:
  Schema: name (STRING), age (INT32), salary (INT64), dept (STRING)

  Row Group 0 (rows 0–99,999):
    name:   offset=0,      size=2.1MB, min="Aaron",  max="Cynthia", nulls=0
    age:    offset=2.1MB,  size=0.4MB, min=18,       max=67,        nulls=12
    salary: offset=2.5MB,  size=0.8MB, min=31000,    max=185000,    nulls=0
    dept:   offset=3.3MB,  size=0.1MB, min="Design", max="Sales",   nulls=0

  Row Group 1 (rows 100,000–199,999):
    ...
</code></pre><p>Pour lire un fichier Parquet, on commence par se positionner à la fin, lire le footer, puis l'utiliser pour localiser exactement les données dont on a besoin. Cette structure permet trois avantages clés : <strong>l'efficacité de projection</strong> (ne lire que les colonnes nécessaires), <strong>la compression</strong> (les column chunks contiennent des données homogènes), et le <strong>predicate pushdown</strong> (sauter des row groups entiers selon les statistiques). Il y a d'autres avantages—le parallélisme grâce aux row groups et la sécurité des types grâce au schéma—mais ces trois-là expliquent l'essentiel de la supériorité de Parquet pour l'analytique.<h3 id=1-efficacite-de-projection>1. Efficacité de projection</h3><p>Passons aux chiffres. Considérons 1 million d'enregistrements d'employés avec 4 colonnes totalisant ~100 Mo. La requête <code>SELECT name, salary</code> n'a besoin que de 2 colonnes.<p>En utilisant le footer de notre exemple précédent : name est à l'offset 0 (2,1 Mo), salary est à l'offset 2,5 Mo (0,8 Mo). Deux seeks, 2,9 Mo transférés. Sur HDD, c'est environ 40 ms au total. On saute 97 % du fichier.<h3 id=2-compression>2. Compression</h3><p>Moins d'octets signifie des E/S encore plus rapides. Les colonnes effectivement lues peuvent être rendues plus compactes encore.<p>Dans chaque column chunk, toutes les valeurs partagent le même type, et en pratique elles suivent souvent des motifs : catégories répétées, timestamps séquentiels, clés triées. Parquet exploite ces motifs via l'<strong>encodage</strong> : des transformations propres à chaque colonne, appliquées au niveau des pages.<p><strong>L'encodage par dictionnaire</strong> pour les chaînes de caractères à faible cardinalité (peu de valeurs uniques). Considérons 8 noms de départements répétés sur 1 million de lignes. Au lieu de stocker « Engineering » 200 000 fois (~12 octets chacun), on construit un dictionnaire associant chaque valeur unique à un petit entier : <code>{0: "Design", 1: "Engineering", ...}</code>. Puis on stocke juste les codes entiers (1 octet chacun) au lieu des chaînes complètes. Compression d'environ 12:1.<p><strong>L'encodage delta</strong> pour les entiers séquentiels. Les timestamps s'incrémentent souvent de petites quantités : <code>[1704067200, 1704067201, 1704067203, ...]</code>. Au lieu de stocker chaque valeur de 8 octets, on stocke la première valeur une fois, puis juste les différences : <code>[1704067200, +1, +2, ...]</code>. Les deltas tiennent en 1–2 octets. Compression d'environ 4–8:1.<p><strong>L'encodage par plages (RLE)</strong> pour les valeurs répétées consécutives. Si les données sont triées, on obtient de longues séquences :<sup class=footnote-reference id=fr-3-1><a href=#fn-3>3</a></sup> <code>Design, Design, ...(50k fois)..., Engineering, ...</code>. Au lieu de répéter la valeur, on la stocke une fois avec un compteur : <code>(Design, 50000), (Engineering, 200000), ...</code>. La compression augmente avec la longueur de la séquence ; une séquence de 50 000 devient une seule paire (valeur, compteur).<p>Après l'encodage, une <strong>compression</strong> générique (Snappy, Zstd ou autres) est appliquée au résultat pour un gain supplémentaire. Les deux bénéficient de la disposition en colonnes : <strong>regrouper les valeurs par colonne expose des motifs qui réduisent la taille du fichier</strong>.<h3 id=3-predicate-pushdown>3. Predicate Pushdown</h3><p>Le predicate pushdown permet de sauter des row groups entiers sans les lire.<p>Un <strong>prédicat</strong> est une condition qui filtre les lignes : la clause <code>WHERE</code> en SQL. Dans un plan d'exécution de requête, les opérations forment une hiérarchie—lecture des données en bas, transformation et filtrage plus haut. « Pushdown » signifie déplacer le filtre vers le bas de cette hiérarchie, du moteur de requête vers la couche de stockage. Au lieu de lire les données puis d'écarter les lignes qui ne correspondent pas, on les saute avant de les lire. Les statistiques min/max du footer rendent cela possible : Parquet peut vérifier si un row group pourrait contenir des correspondances sans lire les données réelles.<p>Requête : <code>SELECT name FROM employees WHERE salary > 200000</code><ol><li>Lire le footer<li>Vérifier les statistiques de salary par row group : <ul><li>Row Group 0 : salary max = 185 000 → <strong>sauter</strong> (aucune ligne ne peut correspondre)<li>Row Group 1 : salary max = 210 000 → <strong>lire</strong> (pourrait avoir des correspondances)<li>Row Group 2 : salary max = 178 000 → <strong>sauter</strong><li>...</ul><li>Ne lire que les chunks name et salary des row groups qui ont survécu</ol><p>Si 2 des 10 row groups survivent, on a éliminé 80 % des E/S avant de lire la moindre donnée réelle.<p>Cela fonctionne aussi pour les strings. Min/max utilisent l'ordre alphabétique, donc si un row group a min="Aaron" et max="Cynthia", une requête pour <code>name = 'Zoe'</code> peut le sauter entièrement.<details><summary>Filtres de Bloom pour les colonnes à haute cardinalité</summary> <p>Pour les colonnes à haute cardinalité comme <code>user_id</code>, min/max est inutile (la plage couvre tout). Les filtres de Bloom offrent une alternative : un tableau de bits avec plusieurs fonctions de hachage qui répond « certainement pas ici » ou « peut-être ici ». Un faux positif (« peut-être ici » alors que la valeur n'y est pas) signifie une lecture inutile. Le taux suit $(1 - e^{-kn/m})^k$ où $k$ est le nombre de fonctions de hachage, $n$ les lignes, $m$ les bits—et il existe une formule en forme close pour le $k$ optimal qui minimise ce taux. Un sujet pour un autre article.</p></details><h2 id=les-compromis>Les compromis</h2><p>Parquet optimise pour les lectures analytiques : beaucoup de lignes, peu de colonnes. Les coûts apparaissent à deux endroits :<p><strong>Les écritures sont coûteuses et inflexibles.</strong> Créer un fichier Parquet nécessite de mettre en mémoire tampon un row group entier (~128 Mo), calculer les statistiques pour chaque column chunk, appliquer l'encodage et compresser. CSV, c'est juste concaténer des strings. Et les fichiers Parquet sont immuables : on ne peut pas ajouter de lignes sans réécrire le fichier (le footer serait invalidé). Avec CSV, <code>echo "new,row" >> file.csv</code> fonctionne tout simplement.<p><strong>Toutes les lectures n'en bénéficient pas.</strong> Les lectures ponctuelles sont terribles : même avec le predicate pushdown, on lit des column chunks entiers (des mégaoctets) pour récupérer une ligne. Les bases de données orientées ligne utilisent des index pour un accès O(log n) à un enregistrement. Et plus on sélectionne de colonnes, moins on gagne. <code>SELECT *</code> lit tout, perdant l'avantage de la projection (bien que la compression aide toujours), et paie le coût de reconstruction pour réassembler les colonnes en lignes.<p>Si la charge de travail est transactionnelle (beaucoup de lectures et écritures d'enregistrements individuels), Parquet est le mauvais choix.<h2 id=a-retenir>À retenir</h2><p>Le format choisi doit correspondre à la charge de travail :<ul><li>Analytique (scanner des millions de lignes, agréger peu de colonnes, filtrer) → Parquet<li>Transactionnel (récupérer/mettre à jour/ajouter des enregistrements individuels par clé) → orienté ligne</ul><p>De nombreux systèmes utilisent les deux. Postgres pour l'application en production, fichiers Parquet (ou un entrepôt de données orienté colonnes comme BigQuery) pour le reporting. Ils servent des objectifs différents.<p>Parquet a tellement dominé la catégorie de l'analytique en colonnes que l'innovation s'est déplacée vers des espaces adjacents : Arrow pour le traitement en mémoire, les lakehouses (Delta Lake, Iceberg, Hudi) pour les transactions et les ajouts par-dessus des fichiers immuables.<p>Le principe sous-jacent est l'asymétrie de latence d'accès : que ce soit les seeks disque ou les allers-retours HTTP, le coût de <em>démarrer</em> une lecture domine le coût de <em>la poursuivre</em>. Organisez les données pour que les octets nécessaires soient contigus, et le tour est joué.<hr><section class=footnotes><ol class=footnotes-list><li id=fn-1><p>Une simplification : les fichiers peuvent être fragmentés sur des blocs disque non contigus, et les systèmes de fichiers ajoutent des couches d'abstraction. Le modèle mental reste valide pour comprendre les compromis de disposition. <a href=#fr-1-1>↩</a></p><li id=fn-2><p>Les SSD éliminent les seeks mécaniques et sont plus tolérants, mais le principe reste : peu de grandes lectures séquentielles battent beaucoup de petites lectures. <a href=#fr-2-1>↩</a></p><li id=fn-3><p>Parquet ne trie pas les données. Il faut trier avant l'écriture. La clé de tri principale bénéficie le plus ; les clés secondaires bénéficient moins, et seulement si elles sont de faible cardinalité. <a href=#fr-3-1>↩</a></p></ol></section></section><p class=credit><em>Cet article a été écrit en collaboration avec <a href=https://claude.ai>Claude</a>.</em><form action=https://buttondown.com/api/emails/embed-subscribe/vinidlidoo class=embeddable-buttondown-form method=post target=_blank><label for=bd-email>Recevez mes nouveaux articles par email.</label><input id=bd-email name=email placeholder=your@email.com type=email><input value="S'abonner" type=submit></form></article></main><link href=https://vinidlidoo.github.io/katex.min.css rel=stylesheet><script defer src=https://vinidlidoo.github.io/js/katex.min.js></script><span class=hidden id=copy-success> Copied! </span><span class=hidden id=copy-init> Copy code to clipboard </span><script defer src=https://vinidlidoo.github.io/js/copyCodeToClipboard.min.js></script></div><footer><section><nav class="socials nav-navs"><ul><li><a class="nav-links no-hover-padding social" rel=" me" href=https://github.com/vinidlidoo> <img alt=github loading=lazy src=https://vinidlidoo.github.io/social_icons/github.svg title=github> </a><li><a class="nav-links no-hover-padding social" rel=" me" href=https://x.com/vinidlidoo> <img alt=x loading=lazy src=https://vinidlidoo.github.io/social_icons/x.svg title=x> </a></ul></nav><nav class=nav-navs></nav><div class=credits><small> <p><p>© 2026 Vincent Ethier</p> Powered by <a href=https://www.getzola.org>Zola</a> & <a href=https://github.com/welpo/tabi>tabi</a> </small></div></section><div class="search-modal js" aria-labelledby=modalTitle id=searchModal role=dialog><h1 class=visually-hidden id=modalTitle>Search</h1><div id=modal-content><div id=searchBar><div aria-hidden=true class=search-icon><svg viewbox="0 -960 960 960" xmlns=http://www.w3.org/2000/svg><path d="M784-120 532-372q-30 24-69 38t-83 14q-109 0-184.5-75.5T120-580q0-109 75.5-184.5T380-840q109 0 184.5 75.5T640-580q0 44-14 83t-38 69l252 252-56 56ZM380-400q75 0 127.5-52.5T560-580q0-75-52.5-127.5T380-760q-75 0-127.5 52.5T200-580q0 75 52.5 127.5T380-400Z"/></svg></div><input aria-controls=results-container aria-expanded=false autocomplete=off id=searchInput placeholder=Search… role=combobox spellcheck=false><div class="close-icon interactive-icon" title="Clear search" id=clear-search role=button tabindex=0><svg viewbox="0 -960 960 960" xmlns=http://www.w3.org/2000/svg><path d="m256-200-56-56 224-224-224-224 56-56 224 224 224-224 56 56-224 224 224 224-56 56-224-224-224 224Z"/></svg></div></div><div id=results-container><div id=results-info><span id=zero_results> No results</span><span id=one_results> 1 result</span><span id=many_results> $NUMBER results</span><span id=two_results> $NUMBER results</span><span id=few_results> $NUMBER results</span></div><div id=results role=listbox></div></div></div></div></footer>